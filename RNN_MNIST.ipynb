{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN: HW5-RNN EX3"
   ]
  },
    
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the first 19 rows of each picture as X (input timestep) and the 20th row as the prediction (y)\n",
    "X_seq, y_seq = list(), list()\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_seq.append(X_train[i, :20, :])\n",
    "    y_seq.append(X_train[i, 20, :])\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 20, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "X_seq = X_seq / 255\n",
    "y_seq = y_seq / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Centering\n",
    "X_seq = X_seq - .5\n",
    "y_seq = y_seq - .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(20, 28)))\n",
    "model.add(Dense(28))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                23808     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 28)                1820      \n",
      "=================================================================\n",
      "Total params: 25,628\n",
      "Trainable params: 25,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 74s 1ms/sample - loss: 0.0299 - acc: 0.3707\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0203 - acc: 0.4148\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0183 - acc: 0.4211\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0170 - acc: 0.4263\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0162 - acc: 0.4319\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0155 - acc: 0.43390s - loss: 0.0155 \n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0151 - acc: 0.4378\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 74s 1ms/sample - loss: 0.0147 - acc: 0.4385\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0143 - acc: 0.4412\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0141 - acc: 0.4439\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0138 - acc: 0.4426\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0136 - acc: 0.4462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f691e0c608>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_seq, y_seq, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"Mnist_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# load model\n",
    "model = load_model('Mnist_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Load the sample damaged image\n",
    "im = Image.open(\"damaged.bmp\")\n",
    "# Resize the image as Mnist images size\n",
    "im = im.resize((28, 28))\n",
    "\n",
    "# Alternatively, any other image from Mnist test images (X_test) could be loaded and damaged on porpose as a test\n",
    "# im = X_test[200]\n",
    "# im[20,:] = np.zeros(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de00c74f08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convet the image to numpy array\n",
    "im = np.array(im)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the first 20 rows of the damaged image as the test sequence to be fed to the model\n",
    "test_img = im[:20,:]\n",
    "\n",
    "# Normalize the test sequence\n",
    "test_img = test_img / 255\n",
    "# Zero Centering\n",
    "test_img = test_img - .5\n",
    "\n",
    "# Resize the test sequence to match the input shape of the model\n",
    "test_img = np.resize(test_img,(1, test_img.shape[0], test_img.shape[1]))\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.4474412 ,   0.3021674 ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   2.6972775 ,   1.2993023 ,\n",
       "         18.854748  , 102.0783    , 195.19188   , 184.09962   ,\n",
       "         66.79467   ,   5.3444815 ,   8.119306  ,   3.171781  ,\n",
       "          0.        ,   3.9834478 ,   6.229766  ,   0.46333194,\n",
       "          0.37410513,   0.6466645 ,   0.        ,   0.49473345]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed the test sequence to the model in order to predict the output sequence (damaged row of the image)\n",
    "yhat = model.predict(test_img, verbose=0)\n",
    "\n",
    "# Since the input sequence was normalized and zero-centered,  \n",
    "# the reverse action has to be taken, such that the predicted row is prepared to be used in the image\n",
    "yhat = yhat + .5\n",
    "yhat = yhat * 255\n",
    "\n",
    "# Since the prediction is an approximation of the missing row, it has to be modified for impermissible values,\n",
    "# such that values less than 0 are rounded up to 0, and values greater than 255 are rounded down to 255\n",
    "yhat = np.where(yhat > 0.0, yhat , 0)\n",
    "yhat = np.where(yhat > 255.0, 255.0 , yhat)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de00c6bc08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now insert the predicted missing row in appropriate row of the damaged image\n",
    "im[20, :] = yhat\n",
    "\n",
    "# Plot the recovered image\n",
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to image\n",
    "im = Image.fromarray(im)\n",
    "# Resize the recovered image to more clearly diplayed\n",
    "im = im.resize((140, 140))\n",
    "# Save the image\n",
    "im.save('Recovered_img.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
